{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5b71f0",
   "metadata": {},
   "source": [
    "# DER系アプローチの分析用ノートブック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0010d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys, json, re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6edca55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例: 物理GPU1番だけを見せる\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c253e74b",
   "metadata": {},
   "source": [
    "## 1) Project root / config / phase 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42abf222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: der-mu\n",
      "dataset   : cifar100\n",
      "device    : [device(type='cuda', index=0)]\n"
     ]
    }
   ],
   "source": [
    "# === プロジェクトルートの指定 ===\n",
    "# Notebook を CIDL-main の直下で開いているなら \".\" で OK\n",
    "PROJECT_ROOT = Path(\"/home/kouyou/ContinualLearning/repexp/PyCIL\").resolve()\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from trainer import _set_device  # 既存のヘルパをそのまま使う\n",
    "from utils.data_manager import DataManager\n",
    "from utils import factory\n",
    "\n",
    "# === 使いたい設定ファイルと、どの phase を可視化するか ===\n",
    "CONFIG_PATH = \"exps/der_mu/baseline0/cifar100.json\"   # 適宜変更\n",
    "PHASE_ID    = 5                                         # ex) タスク3終了時のモデル → phase3.pkl\n",
    "\n",
    "# === json 読み込み → args にする ===\n",
    "with open(CONFIG_PATH) as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "# device を training と同じ形式 (list of torch.device) に変換\n",
    "_set_device(args)\n",
    "\n",
    "print(\"model_name:\", args[\"model_name\"])\n",
    "print(\"dataset   :\", args[\"dataset\"])\n",
    "print(\"device    :\", args[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198c7b1",
   "metadata": {},
   "source": [
    "## 2) Checkpoint path を trainer と同じ規則で組み立てる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8edb76e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_dir : logs/der-mu/baseline0/cifar100/0/10/reproduce_1993_resnet32/\n",
      "ckpt_path: logs/der-mu/baseline0/cifar100/0/10/reproduce_1993_resnet32//phase_5.pkl\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "def _seed_to_str(seed):\n",
    "    # trainer.py は args['seed'] をそのまま format しているので、list/int 両対応にしておく\n",
    "    if isinstance(seed, (list, tuple)):\n",
    "        return str(seed[0]) if len(seed) else \"0\"\n",
    "    return str(seed)\n",
    "\n",
    "def build_ckpt_dir(args, root=PROJECT_ROOT / \"checkpoint\"):\n",
    "    \n",
    "    \"\"\"trainer / BaseLearner.save_checkpoint と同じ規則で checkpoint ディレクトリを作る\"\"\"\n",
    "    init_cls = 0 if args [\"init_cls\"] == args[\"increment\"] else args[\"init_cls\"]\n",
    "    log = \"baseline\" if \"log\" not in args else args[\"log\"]\n",
    "    \n",
    "    ckpt_dir = \"logs/{}/{}/{}/{}/{}/{}_{}_{}/\".format(\n",
    "        args[\"model_name\"],\n",
    "        log,\n",
    "        args[\"dataset\"],\n",
    "        init_cls,\n",
    "        args[\"increment\"],\n",
    "        args[\"prefix\"], args[\"seed\"][0], args[\"convnet_type\"],\n",
    "    )\n",
    "    return ckpt_dir\n",
    "\n",
    "ckpt_dir  = build_ckpt_dir(args)\n",
    "ckpt_path = f\"{ckpt_dir}/phase_{PHASE_ID}.pkl\"\n",
    "\n",
    "print(\"ckpt_dir :\", ckpt_dir)\n",
    "print(\"ckpt_path:\", ckpt_path)\n",
    "\n",
    "# # もし exists が False のときは、pattern で探す fallback も書いておくと楽\n",
    "# if not ckpt_path.exists():\n",
    "#     cand = glob(str(ckpt_dir / f\"phase{PHASE_ID}*.pkl\"))\n",
    "#     print(\"fallback candidates:\", cand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee07db",
   "metadata": {},
   "source": [
    "## 3) DataManager と model を作って checkpoint をロード（DER/TagFex など拡張系対応）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29ae30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-7c2c8aada76e>:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=model._device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded. convnets = 6\n"
     ]
    }
   ],
   "source": [
    "def infer_convnet_count_from_state_dict(state_dict):\n",
    "    # keys like: 'convnets.0.xxx', 'convnets.1.xxx', ...\n",
    "    idxs = []\n",
    "    pat = re.compile(r\"^convnets\\.(\\d+)\\.\")\n",
    "    for k in state_dict.keys():\n",
    "        m = pat.match(k)\n",
    "        if m:\n",
    "            idxs.append(int(m.group(1)))\n",
    "    return (max(idxs) + 1) if idxs else 0\n",
    "\n",
    "def classes_at_task(k, args, total_classnum):\n",
    "    # task k の終了時点での total_classes（BaseLearnerの挙動に合わせる）\n",
    "    init_cls = args[\"init_cls\"]\n",
    "    inc = args[\"increment\"]\n",
    "    num = init_cls + k * inc\n",
    "    return min(num, total_classnum)\n",
    "\n",
    "def build_network_skeleton_for_ckpt(model, state_dict, data_manager, args, phase_id):\n",
    "    \"\"\"state_dict をロード可能な形に network を拡張しておく。\n",
    "    DERNet/TagFexNet 系は update_fc を task 回数ぶん呼ぶ必要がある。\n",
    "    \"\"\"\n",
    "    net = model._network\n",
    "    # DataParallel だと update_fc が面倒なので notebook では使わない前提\n",
    "    if isinstance(net, torch.nn.DataParallel):\n",
    "        net = net.module\n",
    "        model._network = net\n",
    "\n",
    "    convnet_count = infer_convnet_count_from_state_dict(state_dict)\n",
    "    if convnet_count == 0:\n",
    "        # ふつうはありえないが、念のため\n",
    "        convnet_count = phase_id + 1\n",
    "\n",
    "    # 最終クラス数は fc.weight の out_features で確定できる\n",
    "    if \"fc.weight\" in state_dict:\n",
    "        final_classes = state_dict[\"fc.weight\"].shape[0]\n",
    "    else:\n",
    "        # fallback\n",
    "        final_classes = classes_at_task(phase_id, args, data_manager.get_total_classnum())\n",
    "\n",
    "    # すでに update_fc 済みのモデルなら二重に増やさない\n",
    "    existing = len(getattr(net, \"convnets\", [])) if hasattr(net, \"convnets\") else 0\n",
    "\n",
    "    # DER/TagFex 系は convnets を持つ。ここが最重要分岐。\n",
    "    if hasattr(net, \"update_fc\") and hasattr(net, \"convnets\"):\n",
    "        # 必要な回数だけ update_fc を呼ぶ\n",
    "        # task k でのクラス数を与えながら進める（最後だけ final_classes で整合）\n",
    "        total_cls = data_manager.get_total_classnum()\n",
    "        for k in range(existing, convnet_count):\n",
    "            nb = classes_at_task(k, args, total_cls)\n",
    "            # 最後の update_fc は checkpoint の fc 次元に合わせる\n",
    "            if k == convnet_count - 1:\n",
    "                nb = final_classes\n",
    "            net.update_fc(nb)\n",
    "    else:\n",
    "        # 拡張なしモデルは update_fc 1回で十分なことが多い\n",
    "        if hasattr(net, \"update_fc\") and \"fc.weight\" in state_dict:\n",
    "            net.update_fc(state_dict[\"fc.weight\"].shape[0])\n",
    "\n",
    "    return net\n",
    "\n",
    "# --- DataManager & model ---\n",
    "data_manager = DataManager(\n",
    "    dataset_name=args[\"dataset\"],\n",
    "    shuffle=args.get(\"shuffle\", True),\n",
    "    seed=int(_seed_to_str(args.get(\"seed\", 0))),\n",
    "    init_cls=args[\"init_cls\"],\n",
    "    increment=args[\"increment\"],\n",
    ")\n",
    "\n",
    "model = factory.get_model(args[\"model_name\"], args)\n",
    "model._device = args[\"device\"][0]\n",
    "model._network.to(model._device)\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=model._device)\n",
    "state_dict = ckpt[\"model_state_dict\"]\n",
    "\n",
    "# 1) skeleton を作る（update_fc を必要回数）\n",
    "build_network_skeleton_for_ckpt(model, state_dict, data_manager, args, PHASE_ID)\n",
    "\n",
    "# 2) state_dict ロード\n",
    "model._network.load_state_dict(state_dict, strict=True)\n",
    "model._network.to(model._device)\n",
    "\n",
    "# 3) 追加情報（あれば）\n",
    "if \"forget_classes\" in ckpt and hasattr(model, \"forget_classes\"):\n",
    "    model.forget_classes = ckpt[\"forget_classes\"]\n",
    "if \"protos\" in ckpt:\n",
    "    model._protos = ckpt[\"protos\"]\n",
    "\n",
    "model._network.eval()\n",
    "print(\"loaded. convnets =\", len(getattr(model._network, \"convnets\", [])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021c252",
   "metadata": {},
   "source": [
    "## 4) seen / forget / retain クラス集合を作る（MU系なら forget_classes を活用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddb48ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 60\n",
      "forget: []\n",
      "retain (head): [0 1 2 3 4 5 6 7 8 9]  ... total 60\n"
     ]
    }
   ],
   "source": [
    "# checkpoint phase 時点での「見えている」クラス数\n",
    "num_classes = classes_at_task(PHASE_ID, args, data_manager.get_total_classnum())\n",
    "all_seen = np.arange(num_classes)\n",
    "\n",
    "forget_set = set(getattr(model, \"forget_classes\", []))\n",
    "forget = np.array(sorted([c for c in forget_set if c < num_classes]), dtype=int)\n",
    "retain = np.setdiff1d(all_seen, forget)\n",
    "\n",
    "print(\"num_classes:\", num_classes)\n",
    "print(\"forget:\", forget)\n",
    "print(\"retain (head):\", retain[:10], \" ... total\", len(retain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbca26",
   "metadata": {},
   "source": [
    "## 5) Manual forget class 指定（要件2）と unlearn pruning 設定\n",
    "\n",
    "- このセクション以降は **読み込んだ学習済みモデルに対して unlearning 処理だけ**を行います（要件1）。\n",
    "- 忘却クラスはここで **手動で指定**します（要件2）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d284015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 60\n",
      "FORGET_CLASSES: [50, 51]\n",
      "retain classes: 58\n",
      "TARGET_BACKBONE_ID: 5\n"
     ]
    }
   ],
   "source": [
    "# ===== Manual forget classes (EDIT HERE) =====\n",
    "# 例: task5 に含まれる忘却クラス c を指定\n",
    "FORGET_CLASSES = [50,51]   # <-- ここを手で変更\n",
    "\n",
    "# ===== Target backbone selection =====\n",
    "# 基本は「forget class を含むタスクを直接学習した backbone」を対象にする\n",
    "TARGET_BACKBONE_ID = PHASE_ID  # task t の backbone を使うなら通常これでOK（必要なら手動で変更）\n",
    "\n",
    "# ===== Unlearn pruning hyperparams =====\n",
    "LAMBDA_RETAIN = 1.0      # S = I_forget - lambda * I_retain の lambda\n",
    "PRUNE_RATIO   = 0.005    # 上位何割を壊すか（まずは小さめ推奨）\n",
    "MAX_BATCHES_F = 500      # Fisher推定に使う最大バッチ数（計算節約）\n",
    "MAX_BATCHES_R = 25000\n",
    "BATCH_SIZE    = 256\n",
    "NUM_WORKERS   = 4\n",
    "\n",
    "\n",
    "# ===== Finetune data subsampling (NEW) =====\n",
    "# finetuningで使う画像を「1クラスあたり N 枚」にランダムサンプリングする（0/Noneなら全て）\n",
    "N_PER_CLASS_FT = 40\n",
    "FT_SAMPLE_SEED = 0\n",
    "\n",
    "# ===== Recompute seen/forget/retain sets (override) =====\n",
    "num_classes = classes_at_task(PHASE_ID, args, data_manager.get_total_classnum())\n",
    "all_seen = np.arange(num_classes)\n",
    "\n",
    "forget = np.array(sorted([c for c in FORGET_CLASSES if c < num_classes]), dtype=int)\n",
    "retain = np.setdiff1d(all_seen, forget)\n",
    "\n",
    "print(\"num_classes:\", num_classes)\n",
    "print(\"FORGET_CLASSES:\", forget.tolist())\n",
    "print(\"retain classes:\", len(retain))\n",
    "print(\"TARGET_BACKBONE_ID:\", TARGET_BACKBONE_ID)\n",
    "\n",
    "\n",
    "# ===== Masked finetune hyperparams (NEW) =====\n",
    "FT_STEPS =450           # finetune step 数（まずは 100〜500 くらい）\n",
    "FT_LR    = 1e-4          # 小さめ推奨\n",
    "FT_ALPHA_RETAIN = 1.0    # retain CE\n",
    "FT_BETA_KD      = 1.0    # retain KD（unlearn前の挙動を保つ）\n",
    "FT_GAMMA_FORGET = 1.0    # forget CE を上げる強さ\n",
    "FT_TEMP         = 2.0    # KD temperature\n",
    "FT_LOG_EVERY    = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0bad24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# ===== Helpers: device / logits / backbone access =====\n",
    "def _unwrap_net(net):\n",
    "    # DataParallel / DDP を剥がす\n",
    "    if hasattr(net, \"module\"):\n",
    "        return net.module\n",
    "    return net\n",
    "\n",
    "def _get_device_from_model(model):\n",
    "    dev = getattr(model, \"_device\", None)\n",
    "    if isinstance(dev, (list, tuple)) and len(dev):\n",
    "        return dev[0]\n",
    "    if isinstance(dev, torch.device):\n",
    "        return dev\n",
    "    return next(model._network.parameters()).device\n",
    "\n",
    "def _get_logits_from_network_output(out):\n",
    "    # PyCIL系のネットワークは dict を返すことが多い\n",
    "    if isinstance(out, dict):\n",
    "        for k in [\"logits\", \"logit\", \"outputs\", \"output\"]:\n",
    "            if k in out:\n",
    "                return out[k]\n",
    "        # fc が dict を返す場合\n",
    "        if \"fc\" in out and torch.is_tensor(out[\"fc\"]):\n",
    "            return out[\"fc\"]\n",
    "        raise KeyError(f\"Cannot find logits key in out.keys()={list(out.keys())}\")\n",
    "    # tuple/list の場合（(logits, features)など）\n",
    "    if isinstance(out, (tuple, list)) and len(out) > 0:\n",
    "        if torch.is_tensor(out[0]):\n",
    "            return out[0]\n",
    "    # それ以外は logits そのものとみなす\n",
    "    return out\n",
    "\n",
    "def _get_weight_2d(m):\n",
    "    # nn.Linear 以外（SimpleLinear/CosineLinear等）でも weight を拾う\n",
    "    w = getattr(m, \"weight\", None)\n",
    "    if torch.is_tensor(w) and w.ndim == 2:\n",
    "        return w\n",
    "    return None\n",
    "\n",
    "def get_target_backbone(net, bb_id: int):\n",
    "    net = _unwrap_net(net)\n",
    "    # DERNet: net.convnets[bb_id]\n",
    "    if hasattr(net, \"convnets\"):\n",
    "        return net.convnets[bb_id]\n",
    "    # TagFex系など: net.backbones / net.nets 等の可能性\n",
    "    for attr in [\"backbones\", \"nets\", \"models\", \"encoders\"]:\n",
    "        if hasattr(net, attr):\n",
    "            obj = getattr(net, attr)\n",
    "            try:\n",
    "                return obj[bb_id]\n",
    "            except Exception:\n",
    "                pass\n",
    "    raise AttributeError(\"backbone list (e.g., net.convnets) not found.\")\n",
    "\n",
    "def _extract_targets_from_dataset(dataset):\n",
    "    \"\"\"Datasetからラベル配列を取得（できるだけ高速に属性から取る）。返り値は np.ndarray(int64)\"\"\"\n",
    "    cand_attrs = [\"targets\", \"labels\", \"y\", \"_y\", \"_targets\", \"_labels\"]\n",
    "    for a in cand_attrs:\n",
    "        if hasattr(dataset, a):\n",
    "            t = getattr(dataset, a)\n",
    "            try:\n",
    "                import torch\n",
    "                if torch.is_tensor(t):\n",
    "                    t = t.detach().cpu().numpy()\n",
    "            except Exception:\n",
    "                pass\n",
    "            t = np.asarray(t)\n",
    "            if t.ndim == 1 and len(t) == len(dataset):\n",
    "                return t.astype(np.int64)\n",
    "    # Fallback: iterate (遅い可能性あり)\n",
    "    ys = []\n",
    "    for i in range(len(dataset)):\n",
    "        item = dataset[i]\n",
    "        y = item[-1]\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.is_tensor(y):\n",
    "                y = int(y.item())\n",
    "        except Exception:\n",
    "            pass\n",
    "        ys.append(int(y))\n",
    "    return np.asarray(ys, dtype=np.int64)\n",
    "\n",
    "def _sample_indices_per_class(dataset, n_per_class, seed=0):\n",
    "    \"\"\"dataset内の各クラスから最大n_per_class枚ずつサンプリングした index list を返す。\"\"\"\n",
    "    if n_per_class is None or int(n_per_class) <= 0:\n",
    "        return None\n",
    "    n_per_class = int(n_per_class)\n",
    "    y = _extract_targets_from_dataset(dataset)\n",
    "    classes = np.unique(y)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    picked = []\n",
    "    for c in classes:\n",
    "        idx = np.where(y == c)[0]\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        if len(idx) <= n_per_class:\n",
    "            chosen = idx\n",
    "        else:\n",
    "            chosen = rng.choice(idx, size=n_per_class, replace=False)\n",
    "        picked.extend(chosen.tolist())\n",
    "    rng.shuffle(picked)\n",
    "    return picked\n",
    "\n",
    "def build_class_loader(data_manager, class_indices, source=\"train\", mode=\"train\",\n",
    "                       batch_size=128, num_workers=4, shuffle=True,\n",
    "                       n_per_class=None, seed=0):\n",
    "    \"\"\"DataManager.get_datasetでクラス選択した後、必要なら「1クラスあたりn_per_class枚」にサブサンプルしてDataLoaderを返す。\"\"\"\n",
    "    if isinstance(class_indices, np.ndarray):\n",
    "        class_indices = class_indices.tolist()\n",
    "    dataset = data_manager.get_dataset(class_indices, source=source, mode=mode)\n",
    "\n",
    "    sub_idx = _sample_indices_per_class(dataset, n_per_class=n_per_class, seed=seed)\n",
    "    if sub_idx is not None:\n",
    "        dataset = Subset(dataset, sub_idx)\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                      num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_accuracy(model, loader):\n",
    "    dev = _get_device_from_model(model)\n",
    "    model._network.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for _, x, y in loader:\n",
    "        x = x.to(dev, non_blocking=True)\n",
    "        y = y.to(dev, non_blocking=True)\n",
    "        out = model._network(x)\n",
    "        logits = _get_logits_from_network_output(out)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(total, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecc4a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===== Unlearn pruning core (score + mask) =====\n",
    "def fisher_diag_on_loader(model, module, loader, max_batches=50):\n",
    "    \"\"\"module（対象backbone）の各パラメータについて E[(dL/dθ)^2] を推定する（CPUに蓄積）。\"\"\"\n",
    "    dev = _get_device_from_model(model)\n",
    "    model._network.eval()  # BN/Dropoutを固定してスコアを安定化\n",
    "\n",
    "    fisher = {}\n",
    "    for n, p in module.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            fisher[n] = torch.zeros_like(p, device=\"cpu\")\n",
    "\n",
    "    nb = 0\n",
    "    for _, x, y in loader:\n",
    "        x = x.to(dev, non_blocking=True)\n",
    "        y = y.to(dev, non_blocking=True)\n",
    "\n",
    "        model._network.zero_grad(set_to_none=True)\n",
    "        out = model._network(x)\n",
    "        logits = _get_logits_from_network_output(out)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        for n, p in module.named_parameters():\n",
    "            if (not p.requires_grad) or (p.grad is None) or (n not in fisher):\n",
    "                continue\n",
    "            fisher[n] += (p.grad.detach().cpu() ** 2)\n",
    "\n",
    "        nb += 1\n",
    "        if max_batches is not None and nb >= max_batches:\n",
    "            break\n",
    "\n",
    "    for n in fisher:\n",
    "        fisher[n] /= max(nb, 1)\n",
    "    return fisher\n",
    "\n",
    "def compute_unlearn_score(fisher_forget, fisher_retain, lambda_retain=1.0):\n",
    "    # S = I_forget - lambda * I_retain （CPU tensor dict）\n",
    "    score = {}\n",
    "    for n in fisher_forget:\n",
    "        if n in fisher_retain:\n",
    "            score[n] = fisher_forget[n] - lambda_retain * fisher_retain[n]\n",
    "        else:\n",
    "            score[n] = fisher_forget[n].clone()\n",
    "    return score\n",
    "\n",
    "def build_mask_by_score(module, score, prune_ratio=0.01, only_ndim_ge2=True):\n",
    "    \"\"\"score の正の部分を上位 prune_ratio だけ選び、編集対象マスクを返す（weightは変更しない）。\"\"\"\n",
    "    all_scores = []\n",
    "    for n, p in module.named_parameters():\n",
    "        if n not in score:\n",
    "            continue\n",
    "        if only_ndim_ge2 and p.ndim < 2:\n",
    "            continue\n",
    "        s_pos = torch.clamp(score[n], min=0.0)\n",
    "        all_scores.append(s_pos.flatten())\n",
    "\n",
    "    if len(all_scores) == 0:\n",
    "        raise RuntimeError(\"No parameters selected for mask. (Check only_ndim_ge2 or module structure.)\")\n",
    "\n",
    "    all_scores_cat = torch.cat(all_scores)\n",
    "    k = int(prune_ratio * all_scores_cat.numel())\n",
    "    if k <= 0:\n",
    "        raise RuntimeError(f\"prune_ratio too small: {prune_ratio} (k=0)\")\n",
    "\n",
    "    topk = torch.topk(all_scores_cat, k=k, largest=True)\n",
    "    thr = topk.values.min().item()\n",
    "\n",
    "    mask_dict = {}\n",
    "    total_elems = 0\n",
    "    masked_elems = 0\n",
    "\n",
    "    for n, p in module.named_parameters():\n",
    "        if n not in score:\n",
    "            continue\n",
    "        if only_ndim_ge2 and p.ndim < 2:\n",
    "            continue\n",
    "        s_pos = torch.clamp(score[n], min=0.0)\n",
    "        m = (s_pos >= thr)  # CPU bool (True=編集対象)\n",
    "        mask_dict[n] = m\n",
    "        total_elems += m.numel()\n",
    "        masked_elems += int(m.sum().item())\n",
    "\n",
    "    stats = {\n",
    "        \"threshold\": thr,\n",
    "        \"total_elems\": total_elems,\n",
    "        \"masked_elems\": masked_elems,\n",
    "        \"masked_ratio_actual\": masked_elems / max(total_elems, 1),\n",
    "    }\n",
    "    return mask_dict, stats\n",
    "\n",
    "def _register_grad_mask(module, mask_dict):\n",
    "    \"\"\"編集対象(True)以外の勾配を0にする hook を登録する。\"\"\"\n",
    "    handles = []\n",
    "    for n, p in module.named_parameters():\n",
    "        if n not in mask_dict:\n",
    "            continue\n",
    "        m = mask_dict[n].to(p.device)\n",
    "        # float mask\n",
    "        m_f = m.to(dtype=p.dtype)\n",
    "\n",
    "        def hook(grad, m_f=m_f):\n",
    "            return grad * m_f\n",
    "\n",
    "        handles.append(p.register_hook(hook))\n",
    "    return handles\n",
    "\n",
    "def masked_unlearn_finetune(model, target_bb, mask_dict,\n",
    "                            forget_loader, retain_loader=None,\n",
    "                            steps=200, lr=1e-4, wd=0.0,\n",
    "                            alpha_retain=1.0, beta_kd=1.0, gamma_forget=1.0,\n",
    "                            T=2.0, log_every=50):\n",
    "    \"\"\"mask_dict(True=更新可)の箇所以外を固定したまま、forgetを崩し retain を縛る finetuning。\n",
    "    - forget: loss ascent（CEを大きくする）\n",
    "    - retain: CE + distillation（unlearn前の挙動を保つ）\n",
    "    \"\"\"\n",
    "    dev = _get_device_from_model(model)\n",
    "\n",
    "    # 参照モデル（unlearn前）を固定して保存\n",
    "    ref_net = copy.deepcopy(_unwrap_net(model._network)).to(dev).eval()\n",
    "\n",
    "    # optimizer は target_bb の全パラメータを渡す（grad mask で更新箇所だけ通す）\n",
    "    params = [p for p in target_bb.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.Adam(params, lr=lr, weight_decay=wd)\n",
    "\n",
    "    # 勾配マスク hook\n",
    "    handles = _register_grad_mask(target_bb, mask_dict)\n",
    "\n",
    "    # 固定する部分を“完全に固定”するため、初期値を保存（mask外を毎stepで復元）\n",
    "    frozen_snap = {}\n",
    "    for n, p in target_bb.named_parameters():\n",
    "        if n in mask_dict:\n",
    "            m = mask_dict[n].to(p.device)\n",
    "            with torch.no_grad():\n",
    "                frozen_snap[n] = p.detach().clone()  # 全体\n",
    "        else:\n",
    "            frozen_snap[n] = p.detach().clone()\n",
    "\n",
    "    # iterator\n",
    "    it_f = iter(forget_loader)\n",
    "    it_r = iter(retain_loader) if retain_loader is not None else None\n",
    "\n",
    "    model._network.eval()  # BN統計を動かさない（編集範囲を小さくする）\n",
    "\n",
    "    for step in range(1, steps + 1):\n",
    "        try:\n",
    "            _, xf, yf = next(it_f)\n",
    "        except StopIteration:\n",
    "            it_f = iter(forget_loader)\n",
    "            _, xf, yf = next(it_f)\n",
    "\n",
    "        xf = xf.to(dev, non_blocking=True)\n",
    "        yf = yf.to(dev, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        # forget: CE を上げる（= -CE を最小化）\n",
    "        out_f = model._network(xf)\n",
    "        logits_f = _get_logits_from_network_output(out_f)\n",
    "        loss_forget = F.cross_entropy(logits_f, yf)\n",
    "\n",
    "        total_loss = -gamma_forget * loss_forget\n",
    "\n",
    "        # retain: CE + KD\n",
    "        if retain_loader is not None:\n",
    "            try:\n",
    "                _, xr, yr = next(it_r)\n",
    "            except StopIteration:\n",
    "                it_r = iter(retain_loader)\n",
    "                _, xr, yr = next(it_r)\n",
    "\n",
    "            xr = xr.to(dev, non_blocking=True)\n",
    "            yr = yr.to(dev, non_blocking=True)\n",
    "\n",
    "            out_r = model._network(xr)\n",
    "            logits_r = _get_logits_from_network_output(out_r)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ref_out_r = ref_net(xr)\n",
    "                ref_logits_r = _get_logits_from_network_output(ref_out_r)\n",
    "\n",
    "            loss_retain_ce = F.cross_entropy(logits_r, yr)\n",
    "\n",
    "            # KL( current || ref ) で保持\n",
    "            logp = F.log_softmax(logits_r / T, dim=1)\n",
    "            q = F.softmax(ref_logits_r / T, dim=1)\n",
    "            loss_kd = F.kl_div(logp, q, reduction=\"batchmean\") * (T * T)\n",
    "\n",
    "            total_loss = total_loss + alpha_retain * loss_retain_ce + beta_kd * loss_kd\n",
    "\n",
    "        total_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # mask外を復元して完全固定（weight decay 等の影響も排除）\n",
    "        with torch.no_grad():\n",
    "            for n, p in target_bb.named_parameters():\n",
    "                if n not in mask_dict:\n",
    "                    p.copy_(frozen_snap[n])\n",
    "                    continue\n",
    "                m = mask_dict[n].to(p.device)\n",
    "                snap = frozen_snap[n]\n",
    "                # True が更新可なので、False 部分を戻す\n",
    "                p.data[~m] = snap.data[~m]\n",
    "\n",
    "        if (step % log_every) == 0 or step == 1:\n",
    "            msg = f\"[ft step {step:4d}/{steps}] total={float(total_loss.item()):.4f}  forgetCE={float(loss_forget.item()):.4f}\"\n",
    "            if retain_loader is not None:\n",
    "                msg += f\"  retainCE={float(loss_retain_ce.item()):.4f}  KD={float(loss_kd.item()):.4f}\"\n",
    "            print(msg)\n",
    "\n",
    "    # hook cleanup\n",
    "    for h in handles:\n",
    "        h.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acfbfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FT subset] forget N=80  retain N=2320\n",
      "[BEFORE] acc_forget=0.9720  acc_retain=0.8766\n",
      "[MASK] {'threshold': 0.00016308830527123064, 'total_elems': 461872, 'masked_elems': 2309, 'masked_ratio_actual': 0.004999220563272942}\n",
      "[ft step    1/450] total=0.2009  forgetCE=0.1005  retainCE=0.3014  KD=-0.0000\n",
      "[ft step   50/450] total=-0.3711  forgetCE=0.5348  retainCE=0.1615  KD=0.0021\n",
      "[ft step  100/450] total=-0.9144  forgetCE=1.3225  retainCE=0.3852  KD=0.0229\n",
      "[ft step  150/450] total=-1.9316  forgetCE=2.2694  retainCE=0.3200  KD=0.0179\n",
      "[ft step  200/450] total=-1.2350  forgetCE=3.0123  retainCE=1.2755  KD=0.5017\n",
      "[ft step  250/450] total=-2.8964  forgetCE=3.4367  retainCE=0.5103  KD=0.0301\n",
      "[ft step  300/450] total=-3.6712  forgetCE=4.0355  retainCE=0.3384  KD=0.0260\n",
      "[ft step  350/450] total=-3.8939  forgetCE=4.1912  retainCE=0.2044  KD=0.0929\n",
      "[ft step  400/450] total=-4.3975  forgetCE=4.5261  retainCE=0.1015  KD=0.0272\n",
      "[ft step  450/450] total=-4.2395  forgetCE=4.6962  retainCE=0.2849  KD=0.1718\n",
      "[AFTER ] acc_forget=0.0530  acc_retain=0.8587\n"
     ]
    }
   ],
   "source": [
    "# ===== 6) Build forget/retain loaders (train split) =====\n",
    "# 注意: unlearning のため、通常は train split を使う（test を使う場合はここを変える）\n",
    "\n",
    "forget_loader = build_class_loader(\n",
    "    data_manager, forget, source=\"train\", mode=\"train\",\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "\n",
    "# retain は全部だと重いので、必要なら一部クラスだけに絞る／サンプル数を制限する\n",
    "retain_loader = build_class_loader(\n",
    "    data_manager, retain, source=\"train\", mode=\"train\",\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ---- Finetune loaders: sample N images per class ----\n",
    "# NOTE: 評価・Fisher推定は上の full loader を使い、finetune だけサブサンプルを使う\n",
    "forget_loader_ft = build_class_loader(\n",
    "    data_manager, forget, source=\"train\", mode=\"train\",\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True,\n",
    "    n_per_class=N_PER_CLASS_FT, seed=FT_SAMPLE_SEED\n",
    ")\n",
    "retain_loader_ft = build_class_loader(\n",
    "    data_manager, retain, source=\"train\", mode=\"train\",\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True,\n",
    "    n_per_class=N_PER_CLASS_FT, seed=FT_SAMPLE_SEED\n",
    ")\n",
    "\n",
    "print(f\"[FT subset] forget N={len(getattr(forget_loader_ft, 'dataset', []))}  retain N={len(getattr(retain_loader_ft, 'dataset', []))}\")\n",
    "# ===== 7) Evaluate BEFORE =====\n",
    "acc_forget_before = eval_accuracy(model, forget_loader)\n",
    "acc_retain_before = eval_accuracy(model, retain_loader)\n",
    "\n",
    "print(f\"[BEFORE] acc_forget={acc_forget_before:.4f}  acc_retain={acc_retain_before:.4f}\")\n",
    "\n",
    "# ===== 8) Compute Fisher (forget vs retain) on TARGET_BACKBONE =====\n",
    "target_bb = get_target_backbone(model._network, TARGET_BACKBONE_ID)\n",
    "\n",
    "# Fisher 推定のために grad を有効化（freezeされていてもここだけスコアリング/編集したい）\n",
    "for p in target_bb.parameters():\n",
    "    p.requires_grad_(True)\n",
    "\n",
    "f_f = fisher_diag_on_loader(model, target_bb, forget_loader, max_batches=MAX_BATCHES_F)\n",
    "f_r = fisher_diag_on_loader(model, target_bb, retain_loader, max_batches=MAX_BATCHES_R)\n",
    "\n",
    "score = compute_unlearn_score(f_f, f_r, lambda_retain=LAMBDA_RETAIN)\n",
    "\n",
    "# ===== 9) Build mask (do NOT zero weights) =====\n",
    "mask_dict, mask_stats = build_mask_by_score(\n",
    "    target_bb, score, prune_ratio=PRUNE_RATIO, only_ndim_ge2=True\n",
    ")\n",
    "print(\"[MASK]\", mask_stats)\n",
    "\n",
    "# ===== 10) Masked finetune (unlearning) =====\n",
    "# 編集対象(True)以外は固定したまま、forgetを崩してretainを維持するように微調整する\n",
    "masked_unlearn_finetune(\n",
    "    model, target_bb, mask_dict,\n",
    "    forget_loader=forget_loader_ft,\n",
    "    retain_loader=retain_loader_ft,\n",
    "    steps=FT_STEPS,\n",
    "    lr=FT_LR,\n",
    "    wd=0.0,\n",
    "    alpha_retain=FT_ALPHA_RETAIN,\n",
    "    beta_kd=FT_BETA_KD,\n",
    "    gamma_forget=FT_GAMMA_FORGET,\n",
    "    T=FT_TEMP,\n",
    "    log_every=FT_LOG_EVERY\n",
    ")\n",
    "\n",
    "# ===== 11) Evaluate AFTER finetune =====\n",
    "acc_forget_after = eval_accuracy(model, forget_loader)\n",
    "acc_retain_after = eval_accuracy(model, retain_loader)\n",
    "\n",
    "print(f\"[AFTER ] acc_forget={acc_forget_after:.4f}  acc_retain={acc_retain_after:.4f}\")\n",
    "\n",
    "# ===== Optional: save the finetuned model checkpoint (weights only) =====\n",
    "SAVE_FT = False\n",
    "if SAVE_FT:\n",
    "    out_path = Path(str(ckpt_path)).with_suffix(\"\").as_posix() + f\"_unlearn_maskft{FORGET_CLASSES}.pth\"\n",
    "    torch.save({\n",
    "        \"state_dict\": _unwrap_net(model._network).state_dict(),\n",
    "        \"forget_classes\": forget.tolist(),\n",
    "        \"phase_id\": PHASE_ID,\n",
    "        \"target_backbone_id\": TARGET_BACKBONE_ID,\n",
    "        \"mask_stats\": mask_stats,\n",
    "        \"ft\": {\n",
    "            \"steps\": FT_STEPS, \"lr\": FT_LR,\n",
    "            \"alpha_retain\": FT_ALPHA_RETAIN,\n",
    "            \"beta_kd\": FT_BETA_KD,\n",
    "            \"gamma_forget\": FT_GAMMA_FORGET,\n",
    "            \"temp\": FT_TEMP\n",
    "        }\n",
    "    }, out_path)\n",
    "    print(\"saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e8325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b89a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3bab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c88f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e9061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11568e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
